\chapter{Autonomous Driving Background}

Autonomous driving is a complex task. The vehicle collects information about the surrounding environment from its sensors and then it decides its next control input to the actuators of the vehicle. There are two general approaches to this problem: end-to-end driving and decomposition into several subproblems.

The end-to-end driving approach takes the sensor data as an input and maps them to the control inputs. The end-to-end driving algorithm can be implemented for example using a stream of images form a front-facing camera and a neural network trained using supervised or reinforcement learning. It was successfully demonstrated for example in ALVINN, a simple 3-layer neutral network used in the NavLab autonomous vehicle of Carnegie Mellon University in 1989 \cite{ALVINN}, or more recently with a deep convolutional neural network by Nvidia \cite{Nvidia}. End-to-end driving avoids explicit modeling of the world and the vehicle and it relies on the knowledge extracted from the training data or by learning by trial and error during reinforcement learning.

The other approach is to split the complex problem into several smaller problems, which are solved independently. We can split the problem into three main subproblems: Perception, Planning, and Control.

Perception is the process of collecting data from the sensors and processing them to obtain the current state of the world and the internal properties of the vehicle. The task of determining the position of the vehicle on a map is called localization. The sensors which would be used for localization are cameras, radars, ultrasonic sensors, and LIDARs. The data from these sensors can be used to determine distances to nearby obstacles in different directions. Based on the previous known position of the vehicle, the estimate of its movement, and the distances to obstacles in different directions, the position on a known map can be determined using an algorithm such as Adaptive Monte Carlo Localization (AMCL) \cite{AMCL_position_estimation} \cite{AMCL_adaptive_sampling}. In certain scenarios, the relative distances to the obstacles might not be enough to determine correct position. This can happen for example when the vehicle is driving through a straight tunnel and the distances to the walls are constant even though the vehicle is moving. It is useful to combine readings from multiple sensors which provide odometry such as wheel encoders which measure how many times the wheels turn and an intrinsic measurement unit (IMU) with gyroscopes and accelerometers which measures the linear and angular acceleration of the vehicle. The combination of multiple different types of sensors is called sensor fusion. Kalman filter is an example of an algorithm which is frequently used to fuse data from different sources \cite{Kalman_filter}.

The vehicle must also be able to read road signs and road surface markings for driving along public roads. The data from the sensors can also be used to detect obstacles and for obstacle tracking. The type of obstacle is then identified and in the case of dynamic obstacles such as other cars, bicyclists, pedestrians, animals, or moving inanimate objects their movement in time must be predicted to prevent collisions.

The geometry of a car-like vehicle limits its controllability. The vehicle cannot turn while it is stopped and it can only start turning once it is moving forwards or backwards. Usually the only way to control the turning radius is by turning the front wheels and the rear wheels are fixed. In order to be able to make any reasoning about the future states of the vehicle, we must be able to predict the effect of a sequence of control inputs on the motion of the vehicle. Without an accurate model of the vehicle we could select a trajectory which cannot be safely followed, or which would be ineffective. We will discuss vehicle modelling in detail in chapter Vehicle Model.

With the knowledge of the vehicle model, we can search for a plan consisting of control inputs over some time period which will result in a collision-free trajectory through the environment which minimizes some cost function (e.g., the time it will take to reach some goal location). Planning several steps into the future can give us an advantage over a simple end-to-end driving approach. For example, in the case of autonomous racing, the agent can take advantage of the knowledge of the racing track map, and account for the shape of the track hidden around the next corner. We should be able to decide, when to slow down and when to accelerate, as well as at which point to start turning into a corner, in order to reach the best lap times. We call this subproblem trajectory planning.

Executing the sequence of control inputs one by one might cause the vehicle to drive off the track. The trajectory planning algorithm relies on a vehicle model which might not be accurate. The reference trajectory is therefore idealized, and it might not be possible to achieve it exactly by the actual vehicle. It might also lead to a collision with an obstacle on the track which was not known at the time of planning. A trajectory following algorithm chooses the next action based on the current state of the vehicle and the distance to the position, vehicle orientation, and speed at a corresponding point on the reference trajectory. The algorithm should also avoid any unexpected obstacles detected by the sensors.

The actual effects of the control inputs are measured by the sensors and the control algorithm tries to minimize the error between the planned trajectory and the actual trajectory of the vehicle in its next step. This process is referred to in control theory as closed feedback loop.

\section{Requirements}

In this thesis, we will design and develop an autonomous vehicle for the task of autonomous racing. The racing scenario is a simplification of real-world driving. It requires us to avoid collisions and to find efficient trajectories while moving at high speeds and to adapt to unforeseen obstacles on the road. At the same time, this relaxed problem allows us to ignore any traffic rules. We do not have to consider any speed limits, crossroads, or stop signs.

This problem is inspired by the F1/10 competition organized by the University of Pennsylvania and the University of Virginia \cite{F1/10_web}. We will use the resources from this competition to build a similar autonomous vehicle based on an RC car. To evaluate the performance of the vehicle, we will use the criteria of Time Trial Race of F1/10. In the Time Trial Race, the vehicle drives for 5 minutes around a circuit trying to achieve as many laps as possible without a collision with the boundary of the track or with static obstacles on the track. The time of the fastest lap is also recorded.

We will create an autonomous racing agent which utilizes a trajectory planning algorithm to find fast routes along the racing circuit. We will test different algorithms for searching solutions to the planning problem and compare them in a series of experiments on a real-world car model with sensors and an embedded on-board computer.

\section{Related Work}

In this section we will go through several interesting approaches to path and trajectory planning from the area of robotics and autonomous cars.

Shakey the Robot was a project at the Stanford Research Institute in the 1960s. For the purposes of efficient route finding the A* algorithm was designed by Nils J. Nilsson and his coworkers \cite{Nilsson}. This algorithm is widely used for solving various graph search problems thanks to its simplicity, completeness, and optimality. The NavLab autonomous vans of the Carnegie Mellon university was one of the first autonomous vehicles tested on public roads in the 1980s and 1990s. One of the interesting results of their work is the Pure Pursuit control algorithm \cite{Pure_pursuit}.

Steven M. LaValle designed a randomized path planning algorithm for vehicles with kinodynamic driving constraints and high-dimensional configuration spaces called Rapidly-Exploring Random Trees (RRT) \cite{RRT}. This algorithm randomly samples the configuration space and steers the vehicle towards the sampled point in the space. A tree of feasible paths in the configuration space rooted in the starting position is constructed until a path which ends in the goal position is found. The algorithm is probabilistically complete, but it is not optimal. The algorithm was extended by many times in order to converge faster and to be optimal. The optimal variant of the algorithm, RRT* \cite{RRT_star}, is unfortunately hard to use for car-like vehicles.

In 2007, the DARPA Urban Challenge took place in the USA which was successfully completed by several vehicles with different approaches to trajectory planning. The entry from the Carnegie Mellon University, Boss, won the competition. It uses the Anytime D* algorithm for navigation in unstructured environment \cite{Boss}. The Stanford team used an algorithm called Hybrid A* in their vehicle called Junior \cite{Junior}. This algorithm is an extension of the A* algorithm which discretizes the continuous search space into a discrete grid to avoid examining similar configurations multiple times, but it keeps the information about the trajectories in the continuous configuration space to produce smooth feasible trajectories. The team from MIT used modified RRT algorithm in their vehicle \cite{RRT_urban_driving}.
